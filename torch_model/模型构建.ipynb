{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09762c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T08:39:24.434915Z",
     "start_time": "2023-10-09T08:39:24.419696Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878a4e93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:12:14.159898Z",
     "start_time": "2023-10-09T09:12:14.140454Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "    def __init__(self,**kwargs):\n",
    "        # 调用MLP父类Block的构造函数来进行必要的初始化，这样在构造实例时还可以指定其他函数\n",
    "        super(MLP,self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784,256)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256,10)\n",
    "        \n",
    "        \n",
    "    # 定义模型的前向计算，及如何根据输入的x计算返回所需要的模型输出\n",
    "    def forward(self,x):\n",
    "        o = self.act(self.hidden(x))\n",
    "        return self.output(o)\n",
    "\n",
    "# 以上的 MLP 类中⽆须定义反向传播函数。系统将通过⾃动求梯度⽽自动⽣成反向传播所需的 backward 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ea2706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:12:14.822605Z",
     "start_time": "2023-10-09T09:12:14.813392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3021, 0.8880, 0.8507,  ..., 0.9513, 0.5400, 0.7235],\n",
       "        [0.2344, 0.8895, 0.5763,  ..., 0.1281, 0.8798, 0.5630]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2,784)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa1eb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:12:15.086085Z",
     "start_time": "2023-10-09T09:12:15.071136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Net = MLP()\n",
    "print(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c8a0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:12:25.894600Z",
     "start_time": "2023-10-09T09:12:25.827580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0020,  0.0885, -0.0133, -0.0624,  0.0672, -0.1158,  0.1409,  0.1216,\n",
       "         -0.1626, -0.0041],\n",
       "        [-0.0070,  0.1441,  0.0843, -0.1020,  0.0229, -0.1769,  0.1734,  0.0929,\n",
       "         -0.1904, -0.0596]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net(X) # 前向计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70c988",
   "metadata": {},
   "source": [
    "### 神经网络中常见的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "900f1908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:16:09.465774Z",
     "start_time": "2023-10-09T09:16:09.444561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不含参数的层\n",
    "class MyLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def forward(self, x):\n",
    "        return x - x.mean()  \n",
    "\n",
    "layer = MyLayer()\n",
    "layer(torch.tensor([1, 2, 3, 4, 5], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f265db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 含模型参数的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3603a59a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:20:21.898302Z",
     "start_time": "2023-10-09T09:20:21.883037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (1): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (2): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (3): Parameter containing: [torch.float32 of size 4x1]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyListDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyListDense, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            x = torch.mm(x, self.params[i])\n",
    "        return x\n",
    "net = MyListDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bccc5989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:20:28.383107Z",
     "start_time": "2023-10-09T09:20:28.362083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "                'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "                'linear2': nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        self.params.update({'linear3': nn.Parameter(torch.randn(4, 2))}) # 新增\n",
    "\n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5d451",
   "metadata": {},
   "source": [
    "### 二维卷积层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef0607dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:25:54.216612Z",
     "start_time": "2023-10-09T09:25:54.207642Z"
    }
   },
   "outputs": [],
   "source": [
    "# 卷积运算（二维互相关）\n",
    "def corr2d(X, K): \n",
    "    h, w = K.shape\n",
    "    X, K = X.float(), K.float()\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "# 二维卷积层\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5889d7e",
   "metadata": {},
   "source": [
    "### 填充层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75b29bab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:32:57.451866Z",
     "start_time": "2023-10-09T09:32:57.414777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:]) # 排除不关心的前两维:批量和通道\n",
    "\n",
    "\n",
    "# 注意这里是两侧分别填充1⾏或列，所以在两侧一共填充2⾏或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3,padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61deeae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:35:11.633619Z",
     "start_time": "2023-10-09T09:35:11.616402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f2fc1b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:35:34.151530Z",
     "start_time": "2023-10-09T09:35:34.130601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 步长\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee709ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:38:18.142152Z",
     "start_time": "2023-10-09T09:38:18.135165Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b049c52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:39:49.534491Z",
     "start_time": "2023-10-09T09:39:49.462976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]], dtype=torch.float)\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f05b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:39:58.615469Z",
     "start_time": "2023-10-09T09:39:58.598517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225b79c",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4a16d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:58:17.315738Z",
     "start_time": "2023-10-09T09:58:17.293209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 输入图像channel：1；输出channel：6；5x5卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2x2 Max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # 如果是方阵,则可以只使用一个数字进行定义\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # 除去批处理维度的其他所有维度\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b914adc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:58:24.591393Z",
     "start_time": "2023-10-09T09:58:24.572050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e431ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:59:28.120552Z",
     "start_time": "2023-10-09T09:59:28.114466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0451,  0.0285,  0.0289, -0.1551, -0.0234, -0.1609,  0.0671,  0.0436,\n",
      "         -0.0986, -0.0703]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce4aa467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:59:29.338045Z",
     "start_time": "2023-10-09T09:59:29.329078Z"
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52367179",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd758288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T10:04:07.815050Z",
     "start_time": "2023-10-09T10:04:07.801098Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f9c9d8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T10:04:08.229272Z",
     "start_time": "2023-10-09T10:04:08.021094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "        net = AlexNet()\n",
    "print(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
